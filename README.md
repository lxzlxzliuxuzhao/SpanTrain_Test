# SpanTrain_Test
## 🔥实验环境配置
### 实验设备数目说明
* 使用7台服务器进行端到端性能实验、并行策略有效性实验、消融实验、训练耗时分析、系统开销分析实验；
* 使用2、4、8、12、16台服务器进行可扩展性实验。
实验环境设置
云服务器节点使用4张3090；边服务器节点使用2张3090；端设备节点使用1张3090
7台服务器
2台服务器模拟云节点，2台服务器模拟边，3台服务器模拟端设备；
设置两种环境，分别是：
* 边边、边端、边边不限速，云边、云端连接速率设置到100Mbps
* 整个环境不限速，各节点互联速度大概达到500Mbps以上
可拓展性实验

|            | 云设备数目 | 边设备数目 | 端设备数目 |
|------------|------------|------------|------------|
| 2          | 1          | 1          | 0          |
| 4          | 2          | 1          | 1          |
| 8          | 3          | 2          | 3          |
| 12         | 3          | 3          | 3          |
| 16         | 4          | 6          | 6          |


### 🐵端到端性能实验（14日）
在7台服务器的两种环境配置下实验，先进行环境1下面的实验，选用32 Batch Size的先进行实验
选择的模型和数据集
ResNet50、Resnet105、EfficientNet、Bert-small、GPT-2
分别沿用11月的数据集即可
对比的方法
对比的方法如下：
* Pytorch-DDP
* Pytorch-FSDP
* DeepSpeed-ZeRO2
* DeepSpeed-Pipeline
* Gpipe（使用Pytorch原生的Pipeline支持）
分别需要在Batch Size为16、32、64、128分别进行实验，查看性能数据
需要对比的维度
1. 对比吞吐量，即Sample/s
2. 对比模型精度达到80%的训练时间，20个epoch进行一次测试集测试

### 🦝并行策略有效性对比（19日）
在7台服务器的第一种环境配置下实验，第二种先不做
选择的模型和数据集
ResNet50、Resnet105、EfficientNet、Bert-small、GPT-2
分别沿用11月的数据集即可
对比的方法
对比的方法如下：
* Alpa
* Metis
* Hetpipe
* Asteroid
分别需要在Batch Size为16、32、64、128分别进行实验，查看性能数据
先寻找有开源实现的方法，如果时间来不及，可以直接从其他论文中计算相对值，建议先进行Alpa和Hetpipe的实验
需要对比的维度
1. 对比吞吐量，即Sample/s
2. 对比模型精度达到80%的训练时间，20个epoch进行一次测试集测试
3. 对比生成的并行策略，需要输出上述方法生成的并行策略划分，并记录

### 🦓可扩展性实验（24日）
选择的模型和数据集
EfficientNet、Bert-small、GPT-2
分别沿用11月的数据集即可
对比方法
是上述的可拓展性环境配置下，进行实验即可，选取下面方法进行实验：
* Pytorch-DDP
* DeepSpeed-Pipeline
需要对比的维度
1. 对比吞吐量，即Sample/s
2. 对比模型精度达到80%的训练时间，20个epoch进行一次测试集测试
3. 对比生成的并行策略，需要输出上述方法生成的并行策略划分，并记录

### 🐨消融实验（自对比实验，后续设计）

### 🐏训练耗时分析（自对比实验，后续设计）

### 🐭系统开销分析（自对比实验，后续设计）

